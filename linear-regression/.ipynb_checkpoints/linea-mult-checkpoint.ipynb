{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多元线性回归\n",
    "\n",
    "多元线性回归模型的一般形式为：\n",
    "$\n",
    "y = \\theta _0 + \\theta _1x_1 + \\theta _2x_2 + ... + \\theta _nx_n\n",
    "$\n",
    "\n",
    "则对于上述模型，可以得到预测值的模型:$\\hat y^{(i)} = \\theta _0 + \\theta _1X_1^{(i)} + \\theta _2X_2^{(i)} + ... + \\theta _nX_n^{(i)}$\n",
    "\n",
    "也可以写成: $\\hat y^{(i)} = \\theta _0X_0^{(i)} + \\theta _1X_1^{(i)} + \\theta _2X_2^{(i)} + ... + \\theta _nX_n^{(i)}, \\quad (X_0^{(i)}=1)$\n",
    "\n",
    "假设\n",
    "\n",
    "$\\theta = (\\theta _0, \\theta _1, \\theta _2,...,\\theta _n)^T$, \n",
    "$X_{(i)} = (X_0^{(i)}, X_1^{(i)}, X_2^{(i)},...,X_n^{(i)})$\n",
    "\n",
    "则:\n",
    "\n",
    "$\\hat y^{(i)} = X^{(i)} \\cdot \\theta$\n",
    "\n",
    "假设现在有数据集X_b, 则可以写成下面的形式\n",
    "\n",
    "$\n",
    "    X_b=\\begin{pmatrix}\n",
    "    1 & {X_1^{(1)}} & {X_2^{(1)}} & {\\cdots} & {X_n^{(1)}} \\\\\n",
    "    1 & {X_1^{(2)}} & {X_2^{(2)}} & {\\cdots} & {X_n^{(2)}} \\\\\n",
    "    {\\vdots} & {\\vdots} & {\\ddots} & {\\vdots} \\\\\n",
    "    1 & {X_1^{(m)}} & {X_2^{(m)}} & {\\cdots} & {X_n^{(m)}} \\\\\n",
    "    \\end{pmatrix}\n",
    "$\n",
    "\n",
    "$\n",
    "\\theta = \\begin{pmatrix}\n",
    "\\theta _0 \\\\\n",
    "\\theta _1 \\\\\n",
    "\\theta _2 \\\\\n",
    "\\cdots\\\\\n",
    "\\theta _n \\\\\n",
    "\\end{pmatrix}\n",
    "$\n",
    "\n",
    "则数据集的所有预测值就是 $\\hat y = X_b \\cdot \\theta$\n",
    "\n",
    "损失函数为$\\sum_{i=1}^m(y^{(i)} - \\hat y^{(i)})^2$，现在需要求出损失函数的最小值。\n",
    "\n",
    "损失函数可以转换为$(y - X_b \\cdot \\theta)^T (y - X_b \\cdot \\theta) \\quad (T表示转置矩阵)$\n",
    "\n",
    "多元线性回归的正规方程解(Normal Equation) :\n",
    "\n",
    "$\\theta = (X_b^TX_b)^{-1}X_b^Ty \\quad -1 为逆矩阵$\n",
    "\n",
    "对于求解$\\theta$时间复杂度过高，为$O(n^3)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实现多元线性回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LinearRegression:\n",
    "    def __init__(self):\n",
    "        self.coef_ = None # 系数，对应θ1~θn\n",
    "        self.interception_ = None # 截距，对应θ0\n",
    "        self._theta = None\n",
    "    \n",
    "    # 正规方程解训练模型\n",
    "    def fit_normal(self, X_train, y_train):\n",
    "        assert X_train.shape[0] == y_train.shape[0], \\\n",
    "            \"the size of X_train must be equal to the size of y_train\"\n",
    "        X_b = np.hstack([np.ones((len(X_train), 1)), X_train])\n",
    "        self._theta = np.linalg.inv(X_b.T.dot(X_b)).dot(X_b.T).dot(y_train)\n",
    "\n",
    "        self.interception_ = self._theta[0]\n",
    "        self.coef_ = self._theta[1:]\n",
    "        \n",
    "    def predict(self, X_predict):\n",
    "        assert self.interception_ is not None and self.coef_ is not None, \\\n",
    "            \"must fit before predict\"\n",
    "        \n",
    "        assert X_predict.shape[1] == len(self.coef_), \\\n",
    "            \"the feature number of X_predict must be equal to X_train\"\n",
    "        \n",
    "        X_b = np.hstack([np.ones((len(X_predict), 1)), X_predict])\n",
    "        \n",
    "        return X_b.dot(self._theta)\n",
    "    \n",
    "    def score(self, X_test, y_test):\n",
    "        \"\"\"根据测试数据集确定当前模型的准确度\"\"\"\n",
    "        y_predict = self.predict(X_test)\n",
    "        return self.r2_score(y_test, y_predict)\n",
    "    \n",
    "    def r2_score(self, y_true, y_predict):\n",
    "        \"\"\"计算y_true和y_predict之间的R Square\"\"\"\n",
    "        return 1 - self.mean_squared_error(y_true, y_predict)/np.var(y_true)\n",
    "\n",
    "    def mean_squared_error(self, y_true, y_predict):\n",
    "        \"\"\"计算y_true和y_predict之间的MSE\"\"\"\n",
    "        assert len(y_true) == len(y_predict), \\\n",
    "            \"the size of y_true must be equal to the size of y_predict\"\n",
    "\n",
    "        return np.sum((y_true - y_predict)**2) / len(y_true)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return 'linearRegression'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "boston = datasets.load_boston()\n",
    "\n",
    "# 加载数据\n",
    "X = boston.data\n",
    "y = boston.target\n",
    "\n",
    "X = X[y < 50.0]\n",
    "y = y[y < 50.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(490, 13)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 拆分测试数据集合训练数据集\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 训练模型\n",
    "reg = LinearRegression()\n",
    "reg.fit_normal(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34.161435496217081"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.interception_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -1.18919477e-01,   3.63991462e-02,  -3.56494193e-02,\n",
       "         5.66737830e-02,  -1.16195486e+01,   3.42022185e+00,\n",
       "        -2.31470282e-02,  -1.19509560e+00,   2.59339091e-01,\n",
       "        -1.40112724e-02,  -8.36521175e-01,   7.92283639e-03,\n",
       "        -3.81966137e-01])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81298026026584924"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sklean中的回归问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -1.18919477e-01,   3.63991462e-02,  -3.56494193e-02,\n",
       "         5.66737830e-02,  -1.16195486e+01,   3.42022185e+00,\n",
       "        -2.31470282e-02,  -1.19509560e+00,   2.59339091e-01,\n",
       "        -1.40112724e-02,  -8.36521175e-01,   7.92283639e-03,\n",
       "        -3.81966137e-01])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34.161435496246924"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81298026026584758"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.58654121983008989"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "knn_reg = KNeighborsRegressor()\n",
    "knn_reg.fit(X_train, y_train)\n",
    "knn_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 60 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed:    1.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "          metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "          weights='uniform'),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid=[{'weights': ['uniform'], 'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}, {'weights': ['distance'], 'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'p': [1, 2, 3, 4, 5]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = [\n",
    "    {\n",
    "        \"weights\": [\"uniform\"],\n",
    "        \"n_neighbors\": [i for i in range(1, 11)]\n",
    "    },\n",
    "    {\n",
    "        \"weights\": [\"distance\"],\n",
    "        \"n_neighbors\": [i for i in range(1, 11)],\n",
    "        \"p\": [i for i in range(1, 6)]\n",
    "    }\n",
    "]\n",
    "knn_reg = KNeighborsRegressor()\n",
    "grid_search = GridSearchCV(knn_reg, param_grid, n_jobs=-1, verbose=1)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 5, 'p': 1, 'weights': 'distance'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.63409308018685795"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.70443577270379965"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 更多线性回归模型的讨论\n",
    "\n",
    "可解释性：通过排序和数据对应分析，可以看出每种特征对房价的影响有多大以及正相关还是负相关所以线性规划具有很强的可解释性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -1.05574295e-01,   3.52748549e-02,  -4.35179251e-02,\n",
       "         4.55405227e-01,  -1.24268073e+01,   3.75411229e+00,\n",
       "        -2.36116881e-02,  -1.21088069e+00,   2.50740082e-01,\n",
       "        -1.37702943e-02,  -8.38888137e-01,   7.93577159e-03,\n",
       "        -3.50952134e-01])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4,  7, 10, 12,  0,  2,  6,  9, 11,  1,  8,  3,  5])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(lin_reg.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NOX', 'DIS', 'PTRATIO', 'LSTAT', 'CRIM', 'INDUS', 'AGE', 'TAX',\n",
       "       'B', 'ZN', 'RAD', 'CHAS', 'RM'],\n",
       "      dtype='<U7')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston.feature_names[np.argsort(lin_reg.coef_)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boston House Prices dataset\n",
      "===========================\n",
      "\n",
      "Notes\n",
      "------\n",
      "Data Set Characteristics:  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive\n",
      "    \n",
      "    :Median Value (attribute 14) is usually the target\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "http://archive.ics.uci.edu/ml/datasets/Housing\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      "**References**\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "   - many more! (see http://archive.ics.uci.edu/ml/datasets/Housing)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(boston.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
