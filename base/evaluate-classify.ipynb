{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分类算法的评价\n",
    "\n",
    "\n",
    "> 预测的准确度确实是一个很好很直观的评价指标，但是有时候正确率高并不能代表一个算法就好\n",
    "> 比如某个地区某天地震的预测，假设我们有一堆的特征作为地震分类的属性，类别只有两个，0不发生地震、1发生地震。一个不加思考的分类器，对每一个测试用例都将类别划分为0，那么它就可能达到99%的正确率，但真的地震来临时，这个分类器毫无察觉，这个分类带来的损失是巨大的。为什么99%的正确率的分类器却不是我们想要的，因为这里数据分布不均衡，类别1的数据太少，完全错分类别1依然可以达到很高的正确率却忽视了我们关注的东西。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 混淆矩阵\n",
    "\n",
    "混淆矩阵也称误差矩阵，是表示精度评价的一种标准格式，用n行n列的矩阵形式来表示。\n",
    "\n",
    "混淆矩阵的每一列代表了预测类别，每一列的总数表示预测为该类别的数据的数目；每一行代表了数据的真实归属类别，每一行的数据总数表示该类别的数据实例的数目。\n",
    "\n",
    "|   | 预测类别1 | 预测类别2 | 预测类别3 |\n",
    "| :-: | :-: | :-: | :-: |\n",
    "| 真实类别1 | / | / | / |\n",
    "| 真实类别2 | / | / | / |\n",
    "| 真实类别3 | / | / | / |\n",
    "\n",
    "对于二分类问题，则有\n",
    "\n",
    "|   | 0 | 1 |\n",
    "| :-: | :-: | :-: |\n",
    "| 0 | TN(预测negative正确数) | FP(预测positive错误数) |\n",
    "| 1 | FN(预测negative错误数) | TP(预测positive正确数) |\n",
    "\n",
    "T表示预测结果和真实值相同，F则相反\n",
    "\n",
    "N表示`Negative`即0, P表示`Positive`即1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 精准率和召回率\n",
    "\n",
    "精准率表示预测结果为1，且预测正确的概率。公式表示为 $Precision=\\frac {TP}{TP+FP}$\n",
    "\n",
    "召回率表示真实的分类中被成功预测的概率。公式表示为 $Recall=\\frac {TP}{TP + FN}$\n",
    "\n",
    "TPR？FPR?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实现混淆矩阵，准确率和召回率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "X = digits.data\n",
    "y = digits.target.copy()\n",
    "\n",
    "# 构造偏斜的数据\n",
    "y[digits.target==9] = 1\n",
    "y[digits.target!=9] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97555555555555551"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train, y_train)\n",
    "log_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_log_predict = log_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "403"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 预测negative正确数\n",
    "def TN(y_true, y_predict):\n",
    "    assert len(y_true) == len(y_predict)\n",
    "    return np.sum((y_true == 0) & (y_predict == 0))\n",
    "TN(y_test, y_log_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def FP(y_true, y_predict):\n",
    "    assert len(y_true) == len(y_predict)\n",
    "    return np.sum((y_true == 0) & (y_predict == 1))\n",
    "\n",
    "FP(y_test, y_log_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def FN(y_true, y_predict):\n",
    "    assert len(y_true) == len(y_predict)\n",
    "    return np.sum((y_true == 1) & (y_predict == 0))\n",
    "\n",
    "FN(y_test, y_log_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def TP(y_true, y_predict):\n",
    "    assert len(y_true) == len(y_predict)\n",
    "    return np.sum((y_true == 1) & (y_predict == 1))\n",
    "\n",
    "TP(y_test, y_log_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[403,   2],\n",
       "       [  9,  36]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 求混淆矩阵\n",
    "def confusion_matrix(y_true, y_predict):\n",
    "    return np.array([\n",
    "        [TN(y_true, y_predict), FP(y_true, y_predict)],\n",
    "        [FN(y_true, y_predict), TP(y_true, y_predict)]\n",
    "    ])\n",
    "\n",
    "confusion_matrix(y_test, y_log_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94736842105263153"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 精准率\n",
    "def precision_score(y_true, y_predict):\n",
    "    tp = TP(y_true, y_predict)\n",
    "    fp = FP(y_true, y_predict)\n",
    "    try:\n",
    "        return tp / (tp + fp)\n",
    "    except:\n",
    "        return 0.0\n",
    "    \n",
    "precision_score(y_test, y_log_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80000000000000004"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 回归率\n",
    "def recall_score(y_true, y_predict):\n",
    "    tp = TP(y_true, y_predict)\n",
    "    fn = FN(y_true, y_predict)\n",
    "    try:\n",
    "        return tp / (tp + fn)\n",
    "    except:\n",
    "        return 0.0\n",
    "    \n",
    "recall_score(y_test, y_log_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sklearn中的混淆矩阵，精准率和召回率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[403,   2],\n",
       "       [  9,  36]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, y_log_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94736842105263153"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision_score(y_test, y_log_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80000000000000004"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "\n",
    "recall_score(y_test, y_log_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F1 Score\n",
    "\n",
    "精准率和召回率的选取由应用场景决定。有时候更加注重精准率，如股票预测。有时候更加注重召回率，如病人诊断。\n",
    "\n",
    "但有时候需要同时考虑精准率和召回率，这里引入`F1 Score`, 是精准率和召回率的调和平均值\n",
    "\n",
    "$\n",
    "\\frac {1}{F1} = \\frac {1}{2} (\\frac {1}{precision} + \\frac {1}{recall})\n",
    "$\n",
    "\n",
    "$\n",
    "F1 = \\frac {2 * precision * recall}{precision + recall}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f1_score(precision, recall):\n",
    "    try:\n",
    "        return 2 * precision * recall / (precision + recall)\n",
    "    except:\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision = 0.5\n",
    "recall = 0.5\n",
    "f1_score(precision, recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18000000000000002"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision = 0.1\n",
    "recall = 0.9\n",
    "f1_score(precision, recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision = 0.0\n",
    "recall = 1.0\n",
    "f1_score(precision, recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86746987951807231"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score(y_test, y_log_predict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
